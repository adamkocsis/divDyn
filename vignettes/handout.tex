\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{eurosym}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Handout to the R package divDyn v0.6.0 for diversity dynamics from fossil sampling data},
            pdfauthor={Adam T. Kocsis, Carl J. Reddin, Wolfgang Kiessling},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\ImportTok}[1]{{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
\newcommand{\BuiltInTok}[1]{{#1}}
\newcommand{\ExtensionTok}[1]{{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Handout to the R package divDyn v0.6.0 for diversity dynamics from
fossil sampling data}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Adam T. Kocsis, Carl J. Reddin, Wolfgang Kiessling}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-09-18}


\begin{document}
\maketitle

\section{1. Introduction}\label{introduction}

The purpose of this vignette is to guide users through the basic
capabilities of the `divDyn' package. Fossil occurrence databases, such
as the Paleobiology Database (PaleoDB, \url{http://www.paleobiodb.org/},
\url{http://fossilworks.org}) are readily available to be used in
analyses of diversity, extinction and origination patterns (the dynamics
of biodiversity), with a certain toolkit that has become standard since
the creation of the database. Until now, the implementation of most of
these tools have been the responsibilities of individual researchers,
with no software package to rely on. This R package intends to fill this
gap.

\subsection{1.1. Installation}\label{installation}

In order to install this beta version of the package, you have to
download it from GitHub
(\url{http://www.github.com/adamkocsis/divDyn/}). The installation
instructions will be found on this webpage, but the package is planned
to be uploaded to the CRAN servers as well. All questions should be
addressed to Adam Kocsis, the creator and maintainer of the package
(\href{mailto:adam.kocsis@fau.de}{\nolinkurl{adam.kocsis@fau.de}}).

\section{2. Necessary Data}\label{necessary-data}

All functions in the `divDyn' package are built on two fundamental data
structures: a time scale table and an occurrence dataset.

\subsection{2.1. Time scales}\label{time-scales}

The workflow presented here is based on the discretization of geological
time, which is constrained by stratigraphy. These intervals of time
(bins) represent the basic units of the analysis, and their sequence is
coded in the time scale table. Even if we develop a geological model
that outputs robust estimates in a continuous time axis, the calculation
of metrics presented in the package will require discretization. We
added implementations of the basic functionalities for continuous time
(chapter `4.3. Slicing') as well, but we do not deem it as reliable as
using stratigraphic bins for million-year-scale, deep-time analyses. As
age estimates are dependent on the different geological `time scales',
binning the data can change more than necessary, which can have random
effects on the resulting series.

In order to demonstrate the workflow of binned analyses, we added an
example table to the package. This table represents a somewhat altered
form (see below) of the stage-level geological time scale of Ogg et al.
(2016). You can attach this table using the \texttt{data()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(divDyn)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# attach the time scale object}
\KeywordTok{data}\NormalTok{(stages)}
\end{Highlighting}
\end{Shaded}

Every row in this table represents a bin in the timescale. The most
important variable in this table is the slice number (in this case
\texttt{num}). This variable links every occurrence to one of the bins.
You can gather additional information by typing \texttt{?stages} to the
console. You can visualize the timescale by using the \texttt{plots()}
function included in the package:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{shading=} \StringTok{"series"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/tsplot1-1.pdf}

For easier navigation in the plot, the time dimension can be indicated
with three variables: the radiometric dates that serve as coordinates;
boxes of intervals under lowest \texttt{ylim} value of the plot; and
vertical shades over the plotting area. The time scale to be plotted can
be altered by changing the values of the main argument \texttt{tsdat}
and by providing the appropriate column names for the boxes and shading
arguments. In order to use the period names as labels and the stages as
shades, just change the function input accordingly (the \texttt{xlim}
values will limit the x axis plot):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"period"}\NormalTok{, }\DataTypeTok{shading=}\StringTok{"stage"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{59}\NormalTok{:}\DecValTok{81}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/tsplot2-1.pdf}

The function was designed to enable the highest level of customization.
You can customize the distribution of plotting area with the
\texttt{xlim} (accepts exact ages and sequences of bins, see the
examples), \texttt{ylim}, \texttt{prop} and \texttt{gap} arguments, and
the color of the shading. You can also customize the characteristics of
the general plotting (calling \texttt{plot()}, the boxes of time slices
(calling \texttt{rect()}) and the labels within them (calling the
\texttt{text()} function). You can directly control the arguments of
these functions that \texttt{tsplot()} uses to draw the elements of the
timescale by adding the additional arguments as lists to the
\texttt{plot.args}, \texttt{boxes.args} and \texttt{labels.args}
arguments.\\
For instance, if you want your boxes to feature red italic fonts as
labels, just add col=``red'', and font=3 the way you would regularly use
them with the text() function, but wrap them up in a list, and assign it
to the `labels.args' argument:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }
  \DataTypeTok{labels.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{font=}\DecValTok{3}\NormalTok{), }\DataTypeTok{shading.col=}\KeywordTok{c}\NormalTok{(}\StringTok{"white"}\NormalTok{, }\StringTok{"wheat"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/tsplot3-1.pdf}

Naturally, you can use other time scale plotting packages such as the
`geoscale' package developed by J. Bell (2015). These work great for
Phanerozoic scale analyses, but be sure to check the compatibility of
the time scale you use for the binning and the time scale used for
plotting. As we have experience with problems that stemmed from the
incompatibility of analyzing and plotting data, we recommend using your
own timescale for plotting.

\subsection{2.2. Occurrence table}\label{occurrence-table}

The occurrence tables contain unary information about the presence of a
taxon at a specified locality (can be global). In these tables, each
occurrence is represented by a row which has to include a name of the
taxon. This data format is similar to the following example:

\begin{verbatim}
##   tax bin locality
## 1 Sp1   1    first
## 2 Sp1   1   second
## 3 Sp1   2   second
## 4 Sp2   2   second
## 5 Sp3   2    first
## 6 Sp2   3   second
\end{verbatim}

The functions of the package will have to be pointed to this column, by
specifying its name in the \texttt{tax} argument of the function in
question. Additional variables can be added that contain specific
information about the time and locality of the occurrence, as well as
other variables that help with grouping the individual entries
(taxon/collection information). The utility of this long format is in
its unbounded nature, with the acquisition of newer data points the time
and spatial coverage of the dataset can extend without problems.

\subsubsection{2.2.1. Stratigraphic
assignment}\label{stratigraphic-assignment}

Most functions rely on processes that subset the data to contain
occurrences that represent the same time interval. This column can be
specified with setting the \texttt{bin} argument accordingly. However,
to get this column, a number of processes has to be run on the raw data.
Although the package already incorporates functions and data to assign
downloaded occurrences to stratigraphic bins, those will be illustrated
in a separate handout.

\subsubsection{2.2.2. The example file}\label{the-example-file}

In order to demonstrate most capabilities of the package we have added a
fossil occurrence table of Scleractinian corals that we used in an
earlier study (Kiessling and Kocsis, 2015). This subset was downloaded
from the PaleoDB and was extended with information on inferred
photosymbiotic status, growth types, degree of integration, ecological
environment, inferred depth, substrate lithology and latitudinal groups.
Additional details are available by typing \texttt{?corals} to the
console. This dataset is embedded in the package and can be attached
using the data() function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(corals)}
\end{Highlighting}
\end{Shaded}

This dataset was resolved to the 10 my timescale of the PaleoDB
(\texttt{BIN}, now only available through FossilWorks) and the
stage-level time scale (variable \texttt{stg}) that is included in the
package (see Section 2.1, \texttt{stages}). This latter is the basis of
all inference and plotting. The values of the \texttt{stg} column of the
coral table refers to entries in the \texttt{num} column of the
\texttt{stages} table. Please note that this dataset does not include
Holocene occurrences. The occurrences designated with \texttt{stg==95}
are just single entries that include extant genera; therefore all other
entries of this subset are missing, except for the variables linked to
the taxa. The rest of the occurrences represent actual fossils.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils <-}\StringTok{ }\NormalTok{corals[corals$stg!=}\DecValTok{95}\NormalTok{,]}
\CommentTok{# the number of occurrences}
\KeywordTok{nrow}\NormalTok{(fossils)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29544
\end{verbatim}

\section{3. Basic patterns}\label{basic-patterns}

\subsection{3.1. Ranges}\label{ranges}

We can gain preliminary knowledge by examining the basic patterns of the
stratigraphic ranges. Probably the most apparent of these are the
stratigraphic ranges of the taxa, which can be easily summarized in the
FAD-LAD matrix:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fl <-}\StringTok{ }\KeywordTok{fadlad}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can also use the occurrences' own age estimate to calculate the
ranges, just type in ?fadlad to see some more examples. The ranges of
fossil taxa are the primary data quality feedback we can have from the
massive amount of fossil occurrences. You can easilly visualize these
with the \texttt{ranges()} function. To keep things simple, just assign
the age (stage) mean age to the occurrences:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils$mid <-}\StringTok{ }\NormalTok{stages$mid[fossils$stg]}

\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{,}\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{260}\NormalTok{,}\DecValTok{0}\NormalTok{))}

\KeywordTok{ranges}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ranplot-1.pdf}

The function automatically selects the taxa that have ranges that fall
into the \texttt{xlim} values of the open device (you can suppress this
if you want to). If you zoom in with the main plotting function, you can
see this effect. You can also add the taxon labels by setting the
\texttt{labs} argument to \texttt{TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"series"}\NormalTok{,}\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{,}\DecValTok{81}\NormalTok{))}

\KeywordTok{ranges}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid"}\NormalTok{, }\DataTypeTok{labs=}\NormalTok{T, }\DataTypeTok{labels.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{cex=}\FloatTok{0.2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ranplot2-1.pdf}

As you can see from the example above (\texttt{labs.args} argument), the
argumentation of this function works in a similar way to the that of the
\texttt{tsplot()} function. You can get an even more detailed look if
you set the \texttt{filt} argument to \texttt{"orig"}. This will limit
the displayed taxa to those that originated within the interval.
\texttt{occs=TRUE} will also plot the sampled occurrences on the ranges.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"stage"}\NormalTok{, }\DataTypeTok{boxes=}\KeywordTok{c}\NormalTok{(}\StringTok{"stage"}\NormalTok{,}\StringTok{"series"}\NormalTok{),}\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{,}\DecValTok{81}\NormalTok{))}

\KeywordTok{ranges}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid"}\NormalTok{, }\DataTypeTok{labs=}\NormalTok{T, }
  \DataTypeTok{labels.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{cex=}\FloatTok{0.6}\NormalTok{), }\DataTypeTok{filt=}\StringTok{"orig"}\NormalTok{, }\DataTypeTok{occs=}\NormalTok{T)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ranplot3-1.pdf}

This function can also plot the taxa by groups. Here is the same plot,
but by separating the taxa based on symbiotic status:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"stage"}\NormalTok{, }\DataTypeTok{boxes=}\KeywordTok{c}\NormalTok{(}\StringTok{"stage"}\NormalTok{,}\StringTok{"series"}\NormalTok{),}\DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{,}\DecValTok{81}\NormalTok{))}

\KeywordTok{ranges}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid"}\NormalTok{, }\DataTypeTok{labs=}\NormalTok{T, }
  \DataTypeTok{labels.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{cex=}\FloatTok{0.6}\NormalTok{), }\DataTypeTok{filt=}\StringTok{"orig"}\NormalTok{, }\DataTypeTok{occs=}\NormalTok{T, }\DataTypeTok{group=}\StringTok{"ecology"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ranplot4-1.pdf}

You can also plot survivorship curves. The function \texttt{survivors()}
calculates the proportions of survivors from every bin to all the
remaining bins.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{surv <-}\StringTok{ }\KeywordTok{survivors}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can plot these values for every cohort to get survivorship curves.
As these curves can be thought of as products of an exponential decay,
it is customary to log the y axis, which you can do with adding
\texttt{log="y"} to the arguments of the main \texttt{plot()} function
in \texttt{plot.args}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# time scale plot}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }
  \DataTypeTok{xlim=}\KeywordTok{c}\NormalTok{(}\DecValTok{260}\NormalTok{,}\DecValTok{0}\NormalTok{), }\DataTypeTok{ylab=}\StringTok{"proportion of survivors present"}\NormalTok{,}
  \DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DataTypeTok{plot.args=}\KeywordTok{list}\NormalTok{(}\DataTypeTok{log=}\StringTok{"y"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/survTsplotblank-1.pdf}

Then the curves can be plotted for every column with

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# lines for every cohort}
\NormalTok{for(i in }\DecValTok{1}\NormalTok{:}\KeywordTok{ncol}\NormalTok{(surv)) }\KeywordTok{lines}\NormalTok{(stages$mid, surv[,i])}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/survTsplot1-1.pdf}

The values shown here are also called `forward' survivorship
proportions, but you can also plot the `backward' survivorships to see
how certain cohorts emerge over geologic time, by setting the
\texttt{method} argument of the survivors() function appropriately:

\includegraphics{handout_files/figure-latex/survTsplot2-1.pdf}

Large synchronous changes in these curves represent times where major
changes happened in the history of the group. Major extinctions are
apparent on the forward survivorship, whilst major origination episodes
show up on the backward survivorship curves. However, ways that are more
robust exist to quantify the factors that influence diversity.

\subsection{3.2. Sampling parameters}\label{sampling-parameters}

\subsubsection{3.2.1. Basic descriptors}\label{basic-descriptors}

The patterns of the data are constrained by sampling processes. These
can have a direct influence on the patterns of diversity dynamics and
therefore should be taken into consideration when the conclusions are
drawn from the data.

The \texttt{sumstat()} function calculates basic sampling metrics that
characterize the entire dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp <-}\KeywordTok{sumstat}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }
  \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{samp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   bins  occs taxa colls refs gappiness
## 1   41 23229  760  5444 1203 0.5818335
\end{verbatim}

This includes the total number of occurrences, collections, references
and statistics of gappiness. You can also calculate most of these basic
sampling metrics for every bin with the \texttt{binstat()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp <-}\KeywordTok{binstat}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }
  \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## The database contains duplicate occurrences (multiple species/genus).
\end{verbatim}

The message above indicates that multiple entries of the same genus are
present in the same collections. As this is a species-level occurrence
dataset, this is understandable. By default, these entries are omitted
from the calculations above, but you can toggle this manually by setting
the \texttt{duplicates} argument of binstat() accordingly (\texttt{TRUE}
will keep the duplicates, \texttt{FALSE} will omit them - without
notification).

The function calculates the basic bin-wise statistics that do not
require multi-bin pattern recognition (for instance for Alroy's (2008)
three-timer sampling completeness, which is output by the
\texttt{divDyn()} function). Optionally, additional metrics implemented
in the \texttt{indices()} function can be applied to information in
every bin, by adding \texttt{indices=TRUE} to the function call.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{samp <-}\KeywordTok{binstat}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }
  \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{, }\DataTypeTok{indices=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## The database contains duplicate occurrences (multiple species/genus).
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colnames}\NormalTok{(samp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "occs"      "colls"     "refs"      "SIBs"      "occ1"     
##  [6] "occ2"      "ref1"      "ref2"      "u"         "chao1occ" 
## [11] "uPrime"    "chao1ref"  "richness"  "shannon"   "hill2"    
## [16] "dominance" "squares"   "chao2"     "SCOR"
\end{verbatim}

All results of the output of this function can be plotted then in a
straightforward way, by referring to the elements of the data frame. For
instance, the \texttt{occs} element contains the number of sampled
occurrences and \texttt{coll} refers to the number of collections:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar=}\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\CommentTok{# basic plot}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], samp$occs)}
\CommentTok{# the collections (rescaled, other axis)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], samp$colls*}\DecValTok{5}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
  \KeywordTok{axis}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{,}\DataTypeTok{col.ticks=}\StringTok{"blue"}\NormalTok{,}\DataTypeTok{col.axis=}\StringTok{"blue"}\NormalTok{,}
    \DataTypeTok{at=}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{,}\DecValTok{500}\NormalTok{), }\DataTypeTok{labels=}\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{600}\NormalTok{,}\DecValTok{100}\NormalTok{))}
  \KeywordTok{mtext}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DataTypeTok{text=}\StringTok{"number of collections"}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{line=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/occsAndColls-1.pdf}

The \texttt{binstat()} function also calculates other basic statistics
such as the numbers of references, sampled taxa, single-collection taxa,
single-reference taxa, double collection and double reference taxa along
with the sampling coverage estimator Good's \emph{u} (1953), the
coverage estimator suggested by Alroy (\emph{u' }, 2010) that is based
on the number of single-reference taxa.

\subsubsection{3.2.2. Plotting of counts and
proportions}\label{plotting-of-counts-and-proportions}

You can trace the trajectory of the occurrences that have different
attributes through the bins by using the \texttt{parts()} function. This
requires only two arguments: vector of bin identifiers and a vector that
contains the categories entries. The bin identifier also determines the
coordinates along the independent variable (time), so the numerical bin
entries have to be replaced by the age estimates.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# numerical ages, as bins}
\NormalTok{fossils$stgMid <-}\StringTok{ }\NormalTok{stages$mid[fossils$stg]}
\CommentTok{#plotting}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"number of occurences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{))}
\KeywordTok{parts}\NormalTok{(fossils$stgMid, fossils$bath)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/parts-1.pdf}

If you check out \texttt{?parts}, there will be additional examples
using artificial data. In the default case, the category names are
plotted where they are the most abundant. This plot can be even nicer if
you use opacity (RGBA values for colors) and adding a proper legend.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cols <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"#FF0000AA"}\NormalTok{, }\StringTok{"#00FF00AA"}\NormalTok{, }\StringTok{"#0000FFAA"}\NormalTok{)}
\CommentTok{# reorder too}
\NormalTok{reord <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"shal"}\NormalTok{,}\StringTok{"deep"}\NormalTok{,}\StringTok{"uk"}\NormalTok{)}
\NormalTok{plotnames <-}\KeywordTok{c}\NormalTok{(}\StringTok{"shallow"}\NormalTok{, }\StringTok{"deep"}\NormalTok{, }\StringTok{"unknown"}\NormalTok{)}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"the number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{3000}\NormalTok{))}
\KeywordTok{parts}\NormalTok{(fossils$stgMid, fossils$bath, }\DataTypeTok{col=}\NormalTok{cols, }\DataTypeTok{ord=}\NormalTok{reord, }\DataTypeTok{labs=}\NormalTok{F)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{inset=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.01}\NormalTok{), }
  \DataTypeTok{legend=} \NormalTok{plotnames, }\DataTypeTok{fill=}\NormalTok{cols, }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/parts2-1.pdf}

The dominance of shallow occurrences are even more apparent with
proportions. You can use the \texttt{parts} function to plot these,
rather than the counts, by adding \texttt{prop=T} to the function call:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"proportion of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\KeywordTok{parts}\NormalTok{(fossils$stgMid, fossils$bath, }\DataTypeTok{prop=}\NormalTok{T, }\DataTypeTok{col=}\NormalTok{cols, }\DataTypeTok{ord=}\NormalTok{reord, }\DataTypeTok{labs=}\NormalTok{F)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"bottomleft"}\NormalTok{, }\DataTypeTok{inset=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\FloatTok{0.1}\NormalTok{), }
  \DataTypeTok{legend=} \NormalTok{plotnames, }\DataTypeTok{fill=}\NormalTok{cols, }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/parts3-1.pdf}

\subsubsection{3.2.3. Single-collection and single reference
taxa}\label{single-collection-and-single-reference-taxa}

Single-interval taxa were thought to be byproducts of temporary
increases of sampling intensity (Foote and Raup, 1996) in range-based
datasets such as Sepkoski's compendium (2002). This phenomenon urged
researchers to develop metrics that ignore these taxa in calculating
metrics of biodiversity and evolution. Single-collection taxa can be
quickly omitted from the datasets by using the \texttt{omit()} function.
This will return a logical vector, indicating the rows that should be
omitted. The \texttt{om} argument can be set either to omit the
single-collection occurrences (\texttt{om="coll"}). Single-reference
taxa can be omitted in the same way, although the term needs additional
clarification if multiple bins exist. Taxa that were only described in a
single reference (\texttt{om="ref"}). Some taxa appear in multiple bins
and in each of them they are described by only one reference. These you
can omit with \texttt{om="binref"}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{omitColl <-}\StringTok{ }\KeywordTok{omit}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{om=}\StringTok{"coll"}\NormalTok{)}
\NormalTok{omitRef <-}\StringTok{ }\KeywordTok{omit}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{om=}\StringTok{"ref"}\NormalTok{)}
\NormalTok{omitBinref <-}\StringTok{ }\KeywordTok{omit}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{om=}\StringTok{"binref"}\NormalTok{)}
\CommentTok{# the conserved number of occurrences will be}
\KeywordTok{sum}\NormalTok{(!omitColl)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29583
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(!omitRef)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29489
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(!omitBinref)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 29105
\end{verbatim}

\section{4. Raw diversity dynamics}\label{raw-diversity-dynamics}

The main calculations of the package are contained in the
\texttt{divDyn()} function. This function calculates patterns of taxon
occurrences and stratigraphic ranges to derive estimates over time for
richness, origination/extinction rates and sampling probabilities. In
order to calculate these you only need an occurrence table with
variables including the taxon names (\texttt{tax}) and the time
identifiers (\texttt{bin}). The rest of the information in the table
will not be used by the function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ddFirst<-}\KeywordTok{divDyn}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{noNAStart=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The output of the \texttt{divDyn()} function is a \texttt{data.frame}
class object that contains values for each bins in rows. The first
column (\texttt{bin} variable) contains the bin identifiers. The rest of
the variables are explained in the documentation.

\subsection{4.1. Diversity (taxonomic
richness)}\label{diversity-taxonomic-richness}

You read this because you have interests in the changes of diversity.
Calculating time series of diversity does not require additional action
than running the basic \texttt{divDyn()} function.

\subsubsection{4.1.1.Taxon counts}\label{taxon-counts}

All calculations in this function depend on patterns of occurrences in
the bin/taxon matrix. The numbers of taxa that belong to different
categories form the basis of the metrics. These categories are explained
by Foote (1999) and Alroy (2014) and are available in the help file
\texttt{?divDyn}.

\subsubsection{4.1.2. Different metrics of
richness}\label{different-metrics-of-richness}

Calculating time series of diversity does not require additional action
than running the basic \texttt{divDyn()} function. In this package,
among the traditional range-based methods the range-through (variable
\texttt{divRT}) and the boundary-crosser (\texttt{divBC}) diversities
are implemented. Plotting can be also facilitated by matching the
indices of the diversity values in the variables and their numbers. If
the bin numbers are positive integers this is turned on by setting the
\texttt{noNAStart} argument to \texttt{FALSE}, which is the default.
This change results in \texttt{NA}s and zeros in the final table in
rows, which bins are not sampled.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# metrics}
\NormalTok{ddRec <-}\KeywordTok{divDyn}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"range-through richness (diversity)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
\CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages$mid, ddRec$divRT, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddRec-1.pdf}

This plot shows the trajectory of coral diversity over the post-Permian
interval, using raw data and the range-through diversity metric. Besides
the 0 values at the start of the time series (no sampled corals), you
might also notice a sharp increase of richness in the latest intervals.
This could be the result of an effect called the `Pull of the Recent'.
The `Pull of the Recent' (Raup, 1979) is a smearing phenomenon that
arises when range-based methods are calculated from datasets where
sampling probability changes abruptly. As we know the Recent much better
in comparison to other intervals (sampling probability is much higher,
around one), the number of ranges that connect first occurrences of taxa
to the extant time interval (\texttt{stg\ ==\ 95}) is much higher than
those that link two non-Recent time intervals. The results in spur of
diversity as the Recent is approached. On the other hand, omitting the
recent interval (effectively decreasing sampling probability to 0) leads
to edge effects that result in the opposite phenomenon. The discrepancy
between these two approaches can be visualized by the omission of the
recent `occurrences':

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# metrics}
\NormalTok{dd <-}\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"richness (diversity)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
\CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages$mid, ddRec$divRT, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divRT, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"with recent"}\NormalTok{, }\StringTok{"without recent"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddFossils-1.pdf}

Over the last couple of decades, a number of metrics were proposed to
efficiently express diversity given such distorting effects of
incomplete sampling and the discretized time dimension. As these more
straightforward approaches that use range interpolations have known
issues, occurrence datasets, allow the calculation of more direct
estimators, such as sampled-in-bin (SIB, variable \texttt{divSIB})
diversities.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# metrics}
\NormalTok{dd <-}\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"richness (diversity)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
\CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divRT, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divBC, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divSIB, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"RT"}\NormalTok{, }\StringTok{"BC"}\NormalTok{, }\StringTok{"SIB"}\NormalTok{), }
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"blue"}\NormalTok{,   }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddDiv-1.pdf}

Although range-interpolation does not bias the `SIB' metric, it is more
affected by changes of sampling intensity sampling. The three-timer
sampling completeness is an effective expression of changes in sampling
(\texttt{samp3t} variable):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"three-timer sampling completeness"}\NormalTok{)}
  \CommentTok{# lines}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$samp3t, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/samp3t-1.pdf}

The SIB series can be partially corrected by the three-timer
sampling-completeness (Alroy Ã‚Â§ref). Although this can be a convenient
correction it also increases the estimation error. Nevertheless, this is
the least biased estimator for diversity.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"three-timer sampling completeness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{250}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"SIB"}\NormalTok{, }\StringTok{"corrected SIB"} \NormalTok{), }
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddCorr-1.pdf} The
\texttt{omit()} function is also embedded in the \texttt{divDyn()}
function, so that the metrics are calculated after the omission of
poorly sampled taxa (switched off by default). You can add this filter,
by adding (the appropriate \texttt{om} arguments to the
\texttt{divDyn()} function call.

\subsection{4.2. Taxonomic rates}\label{taxonomic-rates}

Analyzing time series of originations and extinctions helps us to
describe not just how diversity changed over time, by also why it
changed. With taxonomic rates we can decompose changes in diversity to
the relative contribution of cladogenetic processes (i.e.~origination,
the birth of a new taxon) and that of the disappearance of taxa
(i.e.~extinction, the death of a taxon). In the discrete time model, the
most straightforward way to express these contributions is through
simple exponential decay models (Raup, 1985). For convenience, these
variables are named as \texttt{extTYPE} and \texttt{oriTYPE} for
extinction and origination rates, respectively.

\subsubsection{4.2.1. Different metrics of
turnover}\label{different-metrics-of-turnover}

In the package, the proportional rates (\texttt{extProp} and
\texttt{oriProp}) and per capita rates (\texttt{extPC} and
\texttt{oriPC}) of Foote (1999), the three-timer rates (\texttt{ext3t}
and \texttt{ori3t}) of Alroy (2008), their corrected counterparts
(\texttt{extC3t} and \texttt{oriC3t}), the gap-filler rates
(\texttt{extGF} and \texttt{oriGF}) of Alroy (2014) and the improved
second-for-third (\texttt{ext2f3} and \texttt{ori2f3}) of Alroy (2015)
are provided.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"extinction rates"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$extPC, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$extGF, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$ext2f3, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"per capita"}\NormalTok{, }\StringTok{"gap-filler"}\NormalTok{, }\StringTok{"second-for-third"}\NormalTok{),}
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddExt-1.pdf}

The documentation of the function (type in console ?divDyn) contains the
formulas for the calculation of the rates. With heterogeneous,
incomplete sampling the metrics have different properties that can be
summarized as follows:

\begin{itemize}
\item
  Proportional `rates': These metrics express what proportion of the
  cohort of taxa disappears until the new interval.
\item
  The per capita rates of Foote (1999) use the range-through assumption
  to establish ranges for the taxa in the dataset. The rate value
  expresses what proportion of the taxa decayed until the end of the
  interval. The method is biased by the Signor-Lipps effect and edge
  effects (Foote 2000).
\item
  The `three-timer' and `corrected three-timer' rates (Alroy, 2008) are
  different estimators of the per capita rates but will converge on them
  when sampling tends to completeness. They use moving windows around
  the focal interval to select data that is more relevant to the focal
  interval. This metric is unbiased by the Signor-Lipps and edge
  effects. The three-timer sampling completeness can be used to correct
  this metric, but it will not improve its susceptibility to random
  sampling error.
\item
  The `gap-filler' rates (Alroy, 2014): gap-filler extinction rates are
  improved versions of the three-timer rates, using four-bin moving
  windows instead of three. This makes the rates less resistant to
  random error (more taxa are recognized by the categorizing procedure)
  and are an improvement on the three-timer rates. The method sometimes
  results in the seemingly nonsensical negative extinction rates, when
  the true extinction rates are near 0.
\item
  The `second-for-third' rates (Alroy, 2015) are further improvement of
  ideas the three-timer and gap-filler rates represent. By adding an
  algorithmic approach the frequency of negative extinction rates are
  further decreased. Extinction and origination proportions described by
  Alroy (2015) can also be used (\texttt{E2f3} and \texttt{O2f3},
  respectively).
\end{itemize}

\subsubsection{4.2.2. Selectivity testing for the per capita
rates}\label{selectivity-testing-for-the-per-capita-rates}

Although extinction and origination rates can provide information about
events and background processes on their own, sometimes it is more
useful to assess them in comparison between taxa. The most frequent way
of doing this is by splitting a group to subsets and comparing the
patterns of turnover in certain intervals between the two groups. In the
case of selectivity testing, an ecologically, taxonomically important
grouping variable indicates that one of the groups has a higher turnover
at a specific point in time. For the sake of convenience in hypothesis
testing for selectivity for one state of the variable (e.g.~heavily
calcified), the available methods assess selectivity between two groups.

The general problem of extinction selectivity is the error estimation of
the rate values. More data (e.g.~more taxa) will lead to more reliable
estimates while, splitting the same dataset to two subsets will lead to
higher uncertainty in the rate estimates for the two rate values in the
selected interval. The selectivity testing incorporates two aspects: (1)
the difference between the two rate values, (2) and whether this
distance is meaningful or not. In practice, these two criteria can be
summarized by whether it is more supported by the data to describe two
rate values, or is it better founded to describe just one. These two
alternatives are sometimes called as \emph{single-rate model} and the
\emph{dual-rate model} (Kiessling and Simpson, 2011; Kiessling and
Kocsis, 2015). In the case that a dual rate model is better supported,
that means that the difference between the two values of rates is
statistically meaningful, and the extinction or origination event
selectively affected the group with the higher value. For example, here
are the raw origination rates of corals, plotted for the \emph{az} and
the \emph{z} group separately and together:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# split by ecology (az = azooxanthellate, z = zooxantehllate)}
  \NormalTok{z<-}\StringTok{ }\NormalTok{fossils[fossils$ecology==}\StringTok{"z"}\NormalTok{,]}
  \NormalTok{az<-}\StringTok{ }\NormalTok{fossils[fossils$ecology==}\StringTok{"az"}\NormalTok{,]}

\CommentTok{# calculate diversity dynamics}
  \NormalTok{ddZ<-}\KeywordTok{divDyn}\NormalTok{(z, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{)}
  \NormalTok{ddAZ<-}\KeywordTok{divDyn}\NormalTok{(az, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{)}

\CommentTok{# origination rate plot}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{54}\NormalTok{:}\DecValTok{95}\NormalTok{, }
  \DataTypeTok{ylab=}\StringTok{"raw per capita originations"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$oriPC, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{1}\NormalTok{, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], ddZ$oriPC, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{1}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], ddAZ$oriPC, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\DecValTok{2}\NormalTok{, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topright"}\NormalTok{, }\DataTypeTok{inset=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.1}\NormalTok{), }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"total"}\NormalTok{, }\StringTok{"z"}\NormalTok{, }\StringTok{"az"}\NormalTok{), }
  \DataTypeTok{lwd=}\DecValTok{2}\NormalTok{, }\DataTypeTok{lty=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/selPrim-1.pdf}

The question that arises in this case is whether some intervals can be
characterized by actually higher origination rates (for \emph{az} taxa
in the Cretaceous), or is this just a sampling artifact. The testing
framework is implemented currently only for the per capita extinction
rates of Foote (1999) in the \texttt{ratesplit} function. The function
will take the occurrence dataset as an argument and will calculate the
rates values similarly to the \texttt{divDyn} function. The function
requires a separator variable for the selection testing (\texttt{sel})
that will be used for splitting the dataset into two (this column has to
have two possible states i.e.~binary code). The implementation of the
process for the symbiotic status is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rs<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{)}
\NormalTok{rs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## integer(0)
## 
## $ori
## [1] 57 59 75 81
\end{verbatim}

The default output of this function by default is a list of two vectors:
\texttt{ext} and \texttt{ori}, extinction rates and origination rates,
respectively. Each vector contains the bin numbers where the dual rate
model is better supported than the single rate model, where selectivity
is plausible. In the example above, selectivity for the extinctions is
unlikely and it is supported for bin 57 (Norian), 59 (Hettangian), 75
(Albian) and 81 (Maastrichtian). The statistical testing in this case is
based on the number of taxa and can be performed in two different ways,
set with the \texttt{method} argument. The less stringent \texttt{binom}
method implements binomial testing, with a significance value set with
the \texttt{alpha} parameter that defaults to 0.05.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rsBin95<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{method=}\StringTok{"binom"}\NormalTok{)}
\NormalTok{rsBin95}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## [1] 62
## 
## $ori
## [1] 57 59 75 79 81 83 88
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rsBin90<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{rsBin90}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## [1] 62 80
## 
## $ori
##  [1] 57 59 65 74 75 76 79 81 82 83 88
\end{verbatim}

The more conservative approach is to use model selection criteria for
the testing of support for the \emph{single } or \emph{dual rate
models}, which involves calculating Akaike Information Criteria and then
Akaike weights. This is the default method (\texttt{method=AIC}). The
\texttt{alpha} argument in this case depicts the minimum Akaike weight
that serves as a threshold for the \emph{dual rate model} to be
supported. As the ratio of these weights represent likelihood ratios, by
default it is set to 0.89 that roughly represents 8 times higher
likelihood for the \emph{dual rate model}. This can be toggled the way
it is deemed useful for the question at hand.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rsAIC0}\FloatTok{.5}\NormalTok{<-}\KeywordTok{ratesplit}\NormalTok{(fossils, }\DataTypeTok{sel=}\StringTok{"ecology"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\NormalTok{rsAIC0}\FloatTok{.5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ext
## [1] 57 66 80 81
## 
## $ori
##  [1] 57 59 65 74 75 76 81 82 83 88 91
\end{verbatim}

In the case above, the 0.5 \texttt{alpha} value indicates that the dual
rate model should be supported if it is more likely than the single rate
model.

This output, listing supported intervals, is useful for plotting the
selectivity values that could be easily visualized by dots. You can add
these to the plot of \emph{z} and \emph{az} coral origination rates by
running:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# select rate values in the intervals of selectivity}
\NormalTok{selIntervals<-}\KeywordTok{cbind}\NormalTok{(ddZ$oriPC, ddAZ$oriPC)[rs$ori,]}
\CommentTok{# which is higher? TRUE: AZ, FALSE: Z}
\NormalTok{groupSelector<-}\KeywordTok{apply}\NormalTok{(selIntervals, }\DecValTok{1}\NormalTok{, function(x) x[}\DecValTok{1}\NormalTok{]<x[}\DecValTok{2}\NormalTok{])}
\CommentTok{# draw the points}
\CommentTok{# for the AZ corals}
\KeywordTok{points}\NormalTok{(}
  \NormalTok{stages$mid[rs$ori[groupSelector]], }
  \NormalTok{ddAZ$oriPC[rs$ori[groupSelector]],}
  \DataTypeTok{pch=}\DecValTok{16}\NormalTok{, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{cex=}\DecValTok{2}\NormalTok{)}
\CommentTok{# for the Z corals}
\KeywordTok{points}\NormalTok{(}
  \NormalTok{stages$mid[rs$ori[!groupSelector]], }
  \NormalTok{ddZ$oriPC[rs$ori[!groupSelector]],}
  \DataTypeTok{pch=}\DecValTok{16}\NormalTok{, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{cex=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/selDotShow-1.pdf} The
\texttt{combine} method will employ both schemes for testing, but with
the default alpha levels, the binomial test would not limit the set of
selective intervals further than the one base on \texttt{AIC}.

Naturally the \texttt{ratesplit()} function can return the
\emph{p}-values of the binomial tests and the Akaike weights by setting
the \texttt{output} argument to \texttt{"full"} .

\subsection{4.3. Slicing}\label{slicing}

The term slicing refers to the discretization of continuous time. The
added option to use a time variable that contains real values allows
users to use different data to express the passing of time. This
addition enables the application of the basic function to examples of
high temporal resolution, where time is close to continuous, or samples
in relative time such as expressed by meters within the section.

\subsubsection{4.3.1. Unique bin values}\label{unique-bin-values}

In the case of the coral dataset, we can try this numerical binning
approach by assigning the estimated age mid points to the occurrences.
This is a very `dirty' way of treating occurrence data as the assumed
uncertainty of the age estimate is practically reduced to 0, and
overlapping intervals that express uncertainty will have different
assigned bins.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils$mid_ma<-}\StringTok{ }\KeywordTok{apply}\NormalTok{(fossils[,}\KeywordTok{c}\NormalTok{(}\StringTok{"max_ma"}\NormalTok{,}\StringTok{"min_ma"}\NormalTok{)], }\DecValTok{1}\NormalTok{, mean)}
\end{Highlighting}
\end{Shaded}

If this column is set as the \texttt{bin} argument, then occurrences
will be treated to represent the same time interval that have the same
value in this column. The entries will be ordered by the function, but
beware that in physical systems time flows from smaller values to larger
values. This means that the ages estimates have to be inversed
additively, otherwise extinctions become originations and vice versa.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fossils$mid_ma<-}\StringTok{ }\NormalTok{-}\StringTok{ }\NormalTok{fossils$mid_ma }
\end{Highlighting}
\end{Shaded}

Now the variable is ready to be used by the \texttt{divDyn()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ddIDbin <-}\StringTok{ }\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid_ma"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Please note that this is example is for illustration purposes only. As
there are too many unique entries in this \texttt{bin} variable, with
the corals, this resolution will be too high to produce potentially
meaningful patterns. Range-through diversities are possibly the closest
to reality with this method. With this type of binning, the \texttt{bin}
variable of the \texttt{divDyn} output contains the ages for the bins,
which you can use for plotting (beware the negative values, plotting
requires positive ones!)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"Diversity, range-through"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{300}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(-ddIDbin$bin, ddIDbin$divRT, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divRT, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"unique mid entries"}\NormalTok{,  }\StringTok{"stg stages"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddBasic-1.pdf}

\subsubsection{4.3.2. Real numbers, sliced
bins}\label{real-numbers-sliced-bins}

A potentially more promising solution is to assign the occurrences that
go along a continuous time scale to regularly spaced bins. To achieve
this discretization, you have to supply a numeric vector to the
\texttt{breaks} argument of the \texttt{divDyn()} function. The entries
in this vector will represent the breakpoints or boundaries of the
interval, similarly to the \texttt{breaks} argument of the
\texttt{cut()} or \texttt{hist()} function in the base R distribution.
For the sake of simplicity, let's try a 10 million year bin resolution.
Keep in mind that the ages are still negative values!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# resolve time}
  \NormalTok{breakPoints <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(-}\DecValTok{270}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\CommentTok{# and calculate diversity dynamics}
  \NormalTok{ddMid10<-}\KeywordTok{divDyn}\NormalTok{(fossils, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"mid_ma"}\NormalTok{, }\DataTypeTok{breaks=}\NormalTok{breakPoints)}
\end{Highlighting}
\end{Shaded}

In this case, the \texttt{bin} variable of the output will contain the
mid ages of the bins. Do not worry about setting the exact values for
the start and end of the age ranges. If no data occurs in the outlined
bins, then the corresponding rows in the table will be empty.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# lines  }
\KeywordTok{lines}\NormalTok{(-ddMid10$bin, ddMid10$divRT, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# new legend}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"age estimates, 10MY"}\NormalTok{,  }
  \StringTok{"stg stages"}\NormalTok{, }\StringTok{"unique mid entries"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{, }\StringTok{"black"}\NormalTok{),}
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/dd10actual-1.pdf} This is
fairly close to the stratigraphically constrained time series.

\section{5. Sampling standardization}\label{sampling-standardization}

\subsection{5.1. Concepts}\label{concepts}

\subsubsection{5.1.1. The goal of sampling
standardization}\label{the-goal-of-sampling-standardization}

Raw patterns of biodiversity are biased by heterogeneous, incomplete
sampling. Consider the built-in example of the coral subset, where both
the number of occurrences and the number of collections vary drastically
over time.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sam <-}\KeywordTok{binstat}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{duplicates=}\NormalTok{F)}
\KeywordTok{cor.test}\NormalTok{(dd$divRT, sam$occs, }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in cor.test.default(dd$divRT, sam$occs, method = "spearman"):
## Cannot compute exact p-value with ties
\end{verbatim}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  dd$divRT and sam$occs
## S = 4708.8, p-value = 4.944e-05
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##      rho 
## 0.589824
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor.test}\NormalTok{(dd$divSIB, sam$occs, }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in cor.test.default(dd$divSIB, sam$occs, method = "spearman"):
## Cannot compute exact p-value with ties
\end{verbatim}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  dd$divSIB and sam$occs
## S = 1453.9, p-value = 9.464e-14
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.8733499
\end{verbatim}

Sampling standardization allows the researcher to answer the question:
would the patterns change, if sampling was homogeneous over time? There
are two ways to answer this question: extrapolation and interpolation.
Extrapolation methods try to infer on information we do not have.
Interpolation methods, on the other hand, omit information to make
sampling intensity comparable. The latter are more frequently employed
in the paleontological context, and is usually referred to as
`subsampling', while the former has more robust applications when
sampling is already quite extensive. Beware: as subsampling omits
information, the result gained by subsampling is not an unequivocal
substitute to the raw patterns, but rather their confirmation!

\subsubsection{5.1.2. The formal representation of
subsampling}\label{the-formal-representation-of-subsampling}

Although rarefaction is defined as a deterministic estimator, due to the
advancement of computational speed, recent implementations of the
process use Monte Carlo estimation to get expected results of the
subsampling procedure. This just means that a random subset of a given
size is taken from the data, the desired statistic (e.g.~taxonomic
richness) is calculated, and these steps are iterated. The omission of
information effectively simulates lower levels of sampling (but
conditioned on the realized sampling).

This general question `what would the pattern would be like?' is not
specific to estimators of richness, but is generalizable to all other
statistics that depend on sampling intensity. If the result of this
estimator (\emph{Res}) is dependent on the information from the time
slice, it is essentially just a function \emph{f} of the data (\emph{D})
at hand with potential additional arguments \emph{argF}:

\[Res= f(D, argF).\]

The same metric can be calculated by using the subsampled data in the
time slice, but first we have to calculate this set with the subsampling
procedure. This is just another function g that outputs a subset of the
input dataset, to which we will refer to as the `trial dataset':

\[sub = g(D, argD)\]

Therefore, the metric in question in a trial is dependent on both the
two functions and their additional arguments. We can generalize such an
implementation of subsampling with the following notation:

\[f(g(D, argG), argF)\]

resulting in the \emph{trial result}. However this only applies to
simple estimates that only use information from a single bin
(e.g.~simple diversity metrics such as SIB). But most other metrics are
dependent on multiple slices, which means that the function result can
be formalized as

\[res = f(D1, D2,... Dn, argF).\]

In order to make sampling standardization work, the subsampling
procedure has to be applied to every bin-specific datasets. This means
that a single trial result will be

\[tri = f(g(D1, argG), g(D2, argG),..., g(Di, argG), argF) \]

As the trial result is the manifestation of the randomness in procedure
g it has to be recalculated iteratively. In order to extract the
expectation of this procedure, the results will also have to be averaged
in some way, both of which are implemented in the \texttt{subsample()}
function. With this notation, the function f is the \emph{applied
function} which can be specified with the \texttt{FUN} argument, the g
is the \emph{subsampler} function, which includes predefined procedures
(will be expanded so that the users can write custom procedures). The
arguments \emph{argF} and \emph{argG} are the \emph{applied} and
\emph{subsampling arguments} respectively. Naturally, you can use the
function with different instances that have the same abstract
representation. The basic arguments of subsampling are discussed in the
next chapter.

\subsection{5.2. Basic arguments}\label{basic-arguments}

Some arguments must be provided in order to make the function run. These
will be demonstrated with the simplest, Classical Rarefaction method
(CR, Raup, 1975). All other subsampling methods (see section `5.4.
Different Subsampling Types) use these input parameters, but most of
them will require additional arguments. In all cases, you will have to
specify the input dataset, the column containing the categories (taxon
names) and the binning variable, by which the data will be dissected to
run the subsampler function. These are the \texttt{dat}, \texttt{tax},
and \texttt{bin} arguments, respectively. As the function is expected to
be used on Paleobiology Database data, the duplicates argument (see
section below on this argument) is set to \texttt{FALSE} by default for
quicker use in these cases. This necessitates the 'coll' argument that
defines the column name of the collection identifiers, which is set to
the database default \texttt{collection\_no}. This variable designates
samples in the occurrence dataset. If you do not have such samples, then
set the duplicates argument to TRUE, which makes it possible to run the
function without such a variable.

\subsubsection{5.2.1. Subsampling level}\label{subsampling-level}

The only other mandatory input is the `level' of subsampling, which can
be specified using the \texttt{q} argument. The exact nature of this
value is dependent on the subsampler function (see section `Different
Subsampling Methods'), but in general it expresses sampling intensity.
For the CR subsampling method, this argument represents the subsampling
quota, the desired number of occurrences in the `trial datasets'.
Increasing values will result in increasingly higher sampled
diversities. The `q' argument cannot be negative. With the subsampling
quota of 40 and 60 occurrences the function outputs the following
results for the coral dataset:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"SIB diversity"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{200}\NormalTok{))}
\CommentTok{# raw diversity}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# subsampling}
  \CommentTok{# with 40 occs.}
  \NormalTok{subCR40 <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subCR40$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \CommentTok{# with 80 occs.}
  \NormalTok{subCR80 <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subCR80$divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}

\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"raw"}\NormalTok{, }\StringTok{"CR, q = 40"}\NormalTok{,}\StringTok{"CR, q = 80"}\NormalTok{),}
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/ddCRBasic-1.pdf}

\subsubsection{5.2.2. The number of
iterations/trials}\label{the-number-of-iterationstrials}

The precision of the simulations can be chosen by changing the number of
iterations the function will run. This can set with the \texttt{iter}
argument that has to be a single positive integer. In general, the more
iterations, the better the results, but the time the function needs to
run has a linear relationship with the iteration number. Most
paleontological examples are stable after a couple hundred iterations.
However, if the result of the function changes with every run, you will
have to increase this number!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"genus richness (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{200}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## subsampled, stable  }
  \NormalTok{subStab <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{30}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subStab$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## subsampled, unstable  }
  \NormalTok{subInstab <-}\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{5}\NormalTok{, }\DataTypeTok{q=}\DecValTok{30}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subInstab$divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"raw"}\NormalTok{, }\StringTok{"CR, q=30, stable"}\NormalTok{,}
    \StringTok{"CR, q=30, unstable"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subIter-1.pdf}

In this example, the red line is based on only 5 iterations, while the
blue one is based on 100. This typically means that the low iteration
number will have similar trajectory to the other series, but will have
more volatility due to the random sampling error.

\subsubsection{\texorpdfstring{5.2.3. The \texttt{duplicates}
argument}{5.2.3. The duplicates argument}}\label{the-duplicates-argument}

In the Paleobiology Database, occurrences are organized in collections,
and are recorded as lists of taxa. These entries optimally are on the
species-level of taxonomic resolution while most analyses operate at the
level of genera. As multiple species can be registered in a single
collection, the same genus name can appear multiple time in the
collection list. This will have an effect on the occurrence-based
subsampling methods. Using the \texttt{duplicates} arguments, you can
toggle whether the surplus entries should be omitted
(\texttt{duplicates=FALSE}, default) or whether they should be kept
(\texttt{duplicates=TRUE}). The omission is applied to the variables
defined in \texttt{tax} and \texttt{coll} variables. In case
\texttt{duplicates=FALSE} the \texttt{coll} argument is mandatory.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## subsampled, stable  }
  \NormalTok{subCRnd <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossils, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{)}
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subCR40$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subCRnd$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR, q=40 (with duplicates)"}\NormalTok{,}
    \StringTok{"CR, q=40"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subDupl-1.pdf} This
particular dataset actually contains multiple genus occurrences, so
changing this argument to \texttt{FALSE} is justified. However, as it
lengthens the function call considerably, the following examples will be
based on data that already had this filtering step:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# indicate identical collection/genus combinations}
\NormalTok{collGenus <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(fossils$collection_no, fossils$genus)}
\CommentTok{# omit the duplicates from the occurrence datasets}
\NormalTok{fossGen <-}\StringTok{ }\NormalTok{fossils[!}\KeywordTok{duplicated}\NormalTok{(collGenus),]}
\end{Highlighting}
\end{Shaded}

Just remember that this step can be skipped by adding
\texttt{duplicates=FALSE} to the \texttt{subsample()} function call.

\subsubsection{\texorpdfstring{5.2.4. The \texttt{useFailed}
argument}{5.2.4. The useFailed argument}}\label{the-usefailed-argument}

The subsampling level can be set as high as the user wants it to be.
Depending on whether the data in the time slices reach the subsampling
quota or not, the time slices can be included or excluded from the
results. If the \texttt{useFailed} argument is set to \texttt{FALSE},
then the time slices that do not have enough information to reach the
subsampling quota will be omitted from the resulting series. This is the
default setting, and if the \emph{applied function} output is a scalar
or a vector, then the corresponding results will be omitted. If
\texttt{useFailed=TRUE} then the bins where the quota is not reached
will be represented in the \emph{trial dataset} with all their sampled
occurrences.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"number of occurrences"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\CommentTok{# subsampled, without failed  }
  \NormalTok{withoutFail<-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{, }\DataTypeTok{useFailed=}\OtherTok{FALSE}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], withoutFail$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# subsampled, with failed }
  \NormalTok{withFail <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{, }\DataTypeTok{useFailed=}\OtherTok{TRUE}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], withFail$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR, q=80, without failed"}\NormalTok{,}
    \StringTok{"CR, q=100, with failed"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subFail-1.pdf}

\subsubsection{\texorpdfstring{5.2.5. The \texttt{keep} and \texttt{rem}
arguments}{5.2.5. The keep and rem arguments}}\label{the-keep-and-rem-arguments}

These arguments handle which bins should be forced to be kept (included)
or removed (excluded) from the \emph{trial dataset}. It accepts a
numeric vector, with the bin identifiers. Positive entries mean that the
bins will be included in the \emph{trial dataset} without subsampling.
This can be useful if you want the inclusion of recent `occurrences' to
demonstrate the `Pull of the Recent' effect. This example uses the
original \texttt{corals} dataset to demonstrate how the argument works
(with duplicates omitted).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"per capita extinction rates"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\NormalTok{## subsampled, excluding the recent occurrences  }
  \NormalTok{sub <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }
    \DataTypeTok{q=}\DecValTok{50}\NormalTok{, }\DataTypeTok{rem=} \DecValTok{95}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sub$extPC, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## subsampled, including the recent}
  \NormalTok{subPR <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(corals, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }
    \DataTypeTok{q=}\DecValTok{50}\NormalTok{, }\DataTypeTok{keep=} \DecValTok{95}\NormalTok{, }\DataTypeTok{duplicates=}\OtherTok{FALSE}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid, subPR$extPC, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\CommentTok{# legend}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"only fossils"}\NormalTok{, }
    \StringTok{"including the recent}\CharTok{\textbackslash{}n}\StringTok{(not subsampled)"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{),}
    \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subIntact-1.pdf}

Between these two curves, neither shows perfectly accurate results. The
per capita rates employ the range-through assumption. The first results
(\texttt{sub}) is biased by edge effects, the closer the end of the time
series is, the higher the rate values are due to decreasing total amount
of range extensions. The inclusion of entries in the second dataset on
the other hand allows the `Pull of the Recent' to depress the extinction
rates of the Late Cenozoic.

\subsubsection{\texorpdfstring{5.2.6. Subsampling `output' and plotting
options}{5.2.6. Subsampling output and plotting options}}\label{subsampling-output-and-plotting-options}

The output type of the subsampling process can be set with the output
argument. This should be dependent on the further use of the function
results. The most direct output is the arithmetic (default) or geometric
means of the trials. They provide almost the same output:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# basic plot}
  \KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
    \DataTypeTok{ylab=}\StringTok{"richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\NormalTok{## arithmetic mean output}
  \NormalTok{subArit <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{output=}\StringTok{"arit"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subArit$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{## geometric mean output  }
  \NormalTok{subGeom <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{output=}\StringTok{"geom"}\NormalTok{)}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subGeom$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
  \KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"arithmetic means"}\NormalTok{, }\StringTok{"geometric means"}\NormalTok{),}
    \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subOutput-1.pdf}

However, the subsampling outputs demonstrate the natural variance
arising from the simulating nature of the process. The results of the
individual trials can be conserved by setting the output argument to
either \texttt{"dist"} or \texttt{"list"}. The difference between these
two options is that \texttt{dist} groups the results of the trials by
the structure of the original function. In the cases when the
\texttt{divDyn()} function is the \emph{applied function} (every example
until now), the output is a list, where all variables are matrices.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## subsampled, dist output }
  \NormalTok{subDist <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
    \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{output=}\StringTok{"dist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# the variables}
\KeywordTok{names}\NormalTok{(subDist)}
\CommentTok{# the dimensions of a single variable}
\KeywordTok{dim}\NormalTok{(subDist$divCSIB)}
\end{Highlighting}
\end{Shaded}

Rows are time slices, while columns represent the individual trials.
These can be visualized by a simple \texttt{for()} loop, and the
arithmetic means can be calculated the regular way.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"subsampled richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{))}

\NormalTok{plottedVar <-}\StringTok{ }\NormalTok{subDist$divCSIB}
\NormalTok{for(i in }\DecValTok{1}\NormalTok{:}\KeywordTok{ncol}\NormalTok{(plottedVar))\{}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], plottedVar[,i], }\DataTypeTok{col=}\StringTok{"#00000099"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\CommentTok{# the mean}
\NormalTok{csibMeans<-}\StringTok{ }\KeywordTok{apply}\NormalTok{(plottedVar,}\DecValTok{1}\NormalTok{, mean, }\DataTypeTok{na.rm=}\NormalTok{T)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], csibMeans , }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{, }\DataTypeTok{lwd=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subMultiRes-1.pdf}

For convenience, this variance can also be plotted with the new
\texttt{shades()} function. That will display the distribution of values
by drawing transparent polygons. The quantiles of each distribution are
calculated, and the same values are then connected (.75 to .75).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"subsampled richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{))}
\KeywordTok{shades}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], plottedVar, }\DataTypeTok{res=}\DecValTok{10}\NormalTok{, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/shades-1.pdf}

Setting the \texttt{res} argument of this function controls the
`quantile resolution'. The higher the number, the more refined the
transparency gradient will be. However, it is more useful to the enter
the exact quantiles to be plotted in the form of a numeric vector:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"subsampled richness of genera (corrected SIB)"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{150}\NormalTok{))}
\KeywordTok{shades}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], plottedVar, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{, }\DataTypeTok{res=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{,}\FloatTok{0.25}\NormalTok{,}\FloatTok{0.75}\NormalTok{,}\FloatTok{0.95}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/shades100-1.pdf}

The function's color argument only accepts colors that are specified
without the alpha channel (for instance \texttt{"\#00000066"} is
impossible, but \texttt{"blue"} or \texttt{"\#4433FF"} are perfectly
viable).

\subsection{5.3. The applied function during the
subsampling}\label{the-applied-function-during-the-subsampling}

By default, executing the \texttt{subsample()} command on the occurrence
data will run the \texttt{divDyn()} function in every iteration, which
is specified by the \texttt{FUN} argument (function \emph{f} in the
notation above). Setting this argument to \texttt{NULL} will not run any
function on the subsampled data subset of the trials (\emph{trial
data}). After all iterations are finished, the data subsets will be
concatenated and the function will output them as a list of length
\texttt{iter}. This option coerces the output type of the function to
\texttt{list}, no other output type is possible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## subsampled }
\NormalTok{subData <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{,}\DataTypeTok{FUN=} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# characteristics}
\KeywordTok{class}\NormalTok{(subData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "list"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(subData)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# columns of the trial dataset}
\KeywordTok{colnames}\NormalTok{(subData[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "genus"          "collection_no"  "family"         "abund_value"   
##  [5] "abund_unit"     "reference_no"   "life_habit"     "diet"          
##  [9] "country"        "geoplate"       "lat"            "lng"           
## [13] "paleolat"       "paleolng"       "period"         "epoch"         
## [17] "subepoch"       "stage"          "early_interval" "late_interval" 
## [21] "max_ma"         "min_ma"         "stg"            "Bin"           
## [25] "env"            "lith"           "latgroup"       "bath"          
## [29] "gensp"          "ecology"        "ecologyMostZ"   "ecologyMostAZ" 
## [33] "ecologyBoth"    "growth"         "integration"    "mid"           
## [37] "stgMid"         "mid_ma"
\end{verbatim}

The advantage of this option is that you can inspect the results of the
subsampling output. You can also iterate a custom function on this
output by using the \texttt{lapply()} interator in base R. The results
of the function will be output as a \texttt{list}.

\subsubsection{5.3.1. Example 1: Checking the number of
occurrences}\label{example-1-checking-the-number-of-occurrences}

One of the functions we can check is the number of occurrences in the
`trial datasets'. By the rules of CR, this should be exactly \texttt{q}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{OCC <-}\StringTok{ }\NormalTok{function(x) }\KeywordTok{table}\NormalTok{(x$stg)}
\CommentTok{# list of trials, each contains the number of occurrences in a bin (vector)}
\NormalTok{subOccs <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(subData, OCC)}
\CommentTok{# one trial}
\NormalTok{subOccs [[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 
## 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
\end{verbatim}

Extracting the central tendency (average of the trials) is more
difficult this way, but some output structures (e.g.~geographic shapes)
might require special treatment that can be written as a custom
function. Anyway, \texttt{subsample()} allows the simplification of this
process, if you set the output argument to `list' and by providing the
custom function as the \texttt{FUN} argument. One rule is that the
function must take the occurrence dataset as an argument, which is
formally called \texttt{dat}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{OCC <-}\StringTok{ }\NormalTok{function(dat) }\KeywordTok{table}\NormalTok{(dat$stg)}
\NormalTok{subOccsInternal <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{,}\DataTypeTok{FUN=} \NormalTok{OCC, }\DataTypeTok{output=}\StringTok{"list"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subOccsInternal[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 
## 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 
## 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40
\end{verbatim}

Whether averaging is possible will be dependent on the output of the
\emph{applied function}. If the output of the vector is scalar, then the
output methods \texttt{"arit"} and \texttt{"geom"} will return a scalar,
and \texttt{"dist"} will return a vector. If the output of the function
is a vector, both \texttt{"arit"} and \texttt{"geom"} will return a
single vector, and \texttt{"dist"} will return a matrix. If the result
of the \emph{applied function} is a \texttt{data.frame}, then the result
of \texttt{"arit"} and \texttt{"geom"} will be a \texttt{data.frame}
(from the result) too. In this case, if the output is \texttt{"dist"},
then the output of the subsample function will be a \texttt{list}, each
of its elements representing one of the variables in the output of the
\emph{applied function}, but instead of containing vectors, they will
contain matrices. This is the case for the \texttt{divDyn()} function.
Running the function \texttt{OCC()} above with the \texttt{"dist"} type
output will produce a matrix of occurrences:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subDistOccs <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{,}\DataTypeTok{FUN=} \NormalTok{OCC, }\DataTypeTok{output=}\StringTok{"dist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(subDistOccs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  int [1:41, 1:100] 40 40 40 40 40 40 40 40 40 40 ...
##  - attr(*, "dimnames")=List of 2
##   ..$ : chr [1:41] "54" "55" "56" "57" ...
##   ..$ : NULL
\end{verbatim}

Note the dimensions of the matrix, which is \texttt{41} times
\texttt{100}, the number of sampled time slices and the number of
subsampling trials. CAUTION: The averaging and the grouping of the
resulting variables is possible because the \emph{applied function} is
run on the total dataset first, which will result in a container
prototype that is used to store the \emph{trial results}. If the
function output structure (i.e.~dimensions) is different when it is run
for the subsets than when it is run on the total dataset, the subsample
function will output an error.

\subsubsection{5.3.2. Example 2: maximum absolute
paleolatitudes}\label{example-2-maximum-absolute-paleolatitudes}

Let's say you are interested in the maximum absolute paleolatitude of
the occurrences. This will be influenced by the number of occurrences,
and should therefore be rechecked with subsampling. You can calculate
this in the raw dataset with the following function, using the known
variable names:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{PL <-}\StringTok{ }\NormalTok{function(dat)\{}
  \NormalTok{tRes<-}\StringTok{ }\KeywordTok{tapply}\NormalTok{(}\DataTypeTok{INDEX=}\NormalTok{dat$stg, }\DataTypeTok{X=}\NormalTok{dat$paleolat, }\DataTypeTok{FUN=}\NormalTok{function(y)\{}
    \KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(y), }\DataTypeTok{na.rm=}\NormalTok{T)}
  \NormalTok{\})}
\KeywordTok{return}\NormalTok{(tRes)}
\NormalTok{\}}
\NormalTok{maxPaLat<-}\StringTok{ }\KeywordTok{PL}\NormalTok{(fossils)}
\end{Highlighting}
\end{Shaded}

This variable certainly increases with age,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor.test}\NormalTok{(maxPaLat, stages$mid[}\DecValTok{54}\NormalTok{:}\DecValTok{94}\NormalTok{], }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  maxPaLat and stages$mid[54:94]
## S = 18336, p-value = 5.307e-05
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## -0.5972125
\end{verbatim}

but it is questionable at this point, whether the increasing number of
occurrences is responsible for this pattern, or whether you would still
see it, if the same number of occurrences were sampled from each time
slice. You can quickly check this association at 20 occurrences and CR
by running:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subMaxPaLat <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{20}\NormalTok{,}\DataTypeTok{FUN=}\NormalTok{PL)}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"maximum sampling paleolatitude"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{54}\NormalTok{:}\DecValTok{94}\NormalTok{], maxPaLat, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{54}\NormalTok{:}\DecValTok{94}\NormalTok{], subMaxPaLat, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\CommentTok{# legend}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"max"}\NormalTok{,}
\StringTok{"subsampled max"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{,}\StringTok{"black"}\NormalTok{),}
\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subPLSmm-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor.test}\NormalTok{(subMaxPaLat, stages$mid[}\DecValTok{54}\NormalTok{:}\DecValTok{94}\NormalTok{], }\DataTypeTok{method=}\StringTok{"spearman"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{5.4. Different subsampling
types}\label{different-subsampling-types}

\subsubsection{5.4.1. Classical Rarefaction
(CR)}\label{classical-rarefaction-cr}

Classical Rarefaction is the most straightforward subsampling method. It
is based on the assumption that the number of occurrences is a direct
proxy for sampling intensity. Although this assumption can be criticized
(see below), the general applicability of the method, and
straightforward interpretation of the results makes it especially useful
for checking the distorting effects of sampling. The arguments of the
subsampling types are summarized at the help page of the subsampling
trial functions (5.4.4.). The traditional classical rarefaction
procedure was expanded to perform unit-based subsampling. In all cases
above, CR used the number of rows within a bin as the units of the
subsampling procedure which is set by the default argument
\texttt{unit=NULL}. However, the calculation can also be run with
multiple rows describing one unit (list) of the subsampling that is
indicated by another variable. This way you can rarefy the data to a
certain number of collections (UW subsampling, see below), references or
whatever, while the all rows forming the units remain intact.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subUWunit <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{10}\NormalTok{, }\DataTypeTok{type=}\StringTok{"cr"}\NormalTok{, }\DataTypeTok{unit=}\StringTok{"collection_no"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{\texorpdfstring{5.4.2. Occurrence-weighted by-list
subsampling
(O\textsuperscript{x}W)}{5.4.2. Occurrence-weighted by-list subsampling (OxW)}}\label{occurrence-weighted-by-list-subsampling-oxw}

By-list subsampling methods use information about how the occurrences
are clustered in lists. In the PaleoDB, these clusters are the
collections that `contain' the occurrences, which are direct products of
sampling. Depending on whether we would like to emphasize the sampling
of collections (related to beta diversity) or the number of entries in
lists, you can use the O\textsuperscript{x}W group of subsampling. Since
the development of SQS (or CBR, see below) these methods have not been
widely applied, but nevertheless, they could be useful in some projects.
The basis of these methods is that collection integrity cannot be broken
during the subsampling procedure. Entire lists are drawn from the
subsampling pool of each time bin, while the number of occurrences are
tracked. These lists are the collections that should be indicated by
setting the \texttt{coll} variable appropriately. When the quota is
reached, no more occurrences are drawn. The rest of the process
(assembly of the \emph{trial dataset}, running the \emph{applied
function}) is the same as with the CR method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subOW <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The output of the occurrence-weighted (OW) type is typically very close
to the output of the corresponding level CR results:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subCR <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{40}\NormalTok{)}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB diversity"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subCR$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subOW$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR - 40"}\NormalTok{, }\StringTok{"OW - 40"}\NormalTok{), }
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subOW-1.pdf}

The reason why the method type is called the O\textsuperscript{x}W is
because, depending on the relative importance of the collections and the
entries within the collection, lists express different aspects of
sampling. This can be taken into consideration with the exponentiation
of the occurrence counts in each collection. In these procedures, the
number of occurrences in each collection will be raised to the power of
\texttt{x} and the sum of the resulting values will be compared to the
set subsampling quota. The simplest way of doing this is to raise the
number of occurrences in a collection to the power of 0, which
effectively means the selection of a certain number of collections in
all different time slices (no matter how many occurrences there are in a
collection it will be 1 if raised to the power of 0). Setting the
\texttt{x} argument to 0, will force this setting. This is sometimes
referred to as the `unweighted subsampling' method, which effectively
means to subsample the data to a certain number of collections in a bin.
In this case the \texttt{q} argument will represent the quota of
collections.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trialsUW <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{20}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{0}\NormalTok{, }\DataTypeTok{FUN=}\NormalTok{binstat)}
\CommentTok{# the number of sampled collections on average in each timeslice}
\NormalTok{trialsUW[}\DecValTok{54}\NormalTok{:}\DecValTok{94}\NormalTok{, }\StringTok{"colls"}\NormalTok{]}
\NormalTok{subUW <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{10}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

By this principle, it is not difficult to see that depending on the size
of the collections, the actual number of occurrences will be somewhat
higher than the quota. You can quickly check the exact number of
occurrences drawn with the \texttt{binstat()} function

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subST <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{20}\NormalTok{,}\DataTypeTok{FUN=}\NormalTok{binstat, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subST[}\DecValTok{54}\NormalTok{:}\DecValTok{94}\NormalTok{, }\StringTok{"occs"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 22.46 22.41 24.13 24.22 24.69 23.65 21.61 24.21 22.00 23.54 22.69
## [12] 26.51 23.22 25.51 28.14 31.76 23.98 26.04 25.83 28.80 29.15 26.96
## [23] 26.62 23.37 26.69 26.47 25.56 24.29 22.58 23.86 22.66 23.62 23.02
## [34] 27.47 26.20 25.15 27.58 24.50 23.68 24.44 25.13
\end{verbatim}

Although there are ways to improve the accuracy of the subsampling
process, the variation induced by this problem is only minuscule
compared to those introduced by sampling and binning uncertainties.
However, typically this \texttt{x} value is set to a value between 1 and
2 (e.g.~1.4). In these cases, you have to calculate the intensity of
sampling. Although there is some discrepancy between the methods, the
overall trajectories are quite similar.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subO2W <-}\StringTok{ }\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{, }
  \DataTypeTok{iter=}\DecValTok{100}\NormalTok{, }\DataTypeTok{q=}\DecValTok{80}\NormalTok{, }\DataTypeTok{type=}\StringTok{"oxw"}\NormalTok{, }\DataTypeTok{x=}\DecValTok{2}\NormalTok{)}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB genus richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subCR$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subOW$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subUW$divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], subO2W$divCSIB, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"CR - 40"}\NormalTok{, }\StringTok{"OW - 40"}\NormalTok{, }\StringTok{"UW - 10"}\NormalTok{, }\StringTok{"O2W - 80"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subO2-1.pdf}

\subsubsection{5.4.3. Shareholder Quorum Subsampling
(SQS)}\label{shareholder-quorum-subsampling-sqs}

As intuitive as the CR approach is to understand, the method has been
criticized for be being `unfair' (Alroy, 2010). The results of CR will
not reflect changes of richness appropriately, if two localities with
different diversities are compared and their total richnesses are not
equal. This can be visualized by progressively lowering the subsampling
quota for CR, which will result in not just decreased levels of richness
but also in a pronounced decrease in variance (Alroy, 2010b). This
effect can be illustrated by rerunning CR iteratively with progressively
lower quotas.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# repeat CR subsampling for a set of quotas}
\NormalTok{quotas<-}\KeywordTok{seq}\NormalTok{(}\DecValTok{70}\NormalTok{,}\DecValTok{10}\NormalTok{,-}\DecValTok{10}\NormalTok{)}
\NormalTok{for(i in quotas)\{}
   \CommentTok{# actual CR }
   \NormalTok{cr<-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\NormalTok{i,}\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }
    \DataTypeTok{useFailed=}\OtherTok{FALSE}\NormalTok{)}
  \CommentTok{# store output}
  \KeywordTok{assign}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"cr"}\NormalTok{, i, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{), cr)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The code above reruns the CR algorithm on the dataset with 70, 60, 50
\ldots{} and 10 occurrences as the quota of the subsampling. Then the
results can be plotted with:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{90}\NormalTok{))}
\NormalTok{for(i in quotas)\{}
  \NormalTok{current <-}\StringTok{ }\KeywordTok{get}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"cr"}\NormalTok{, i, }\DataTypeTok{sep=}\StringTok{""}\NormalTok{))}
  \KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], current $divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/subCRmanyShow-1.pdf}

As the subsampling quota decreases, so does the mean value of richness,
and also the relative deviation of the series. The Shareholder Quorum
subsampling approach (Alroy, 2010) effectively circumvents this problem
by using a different proxy for sampling completeness, other than the
number of occurrences. Rather than looking at the basic unary
information of occurrences, the SQS method assesses sampling with
frequency coverage. Coverage is an intuitive way to express the
completeness of sampling. In the species sampling pool all species have
a frequency (F\textsuperscript{k}) that sum up to 1. In this sense, the
coverage of a sample is the sum of species frequencies in the original
sampling pool (F\textsuperscript{k}), but only for those species that
actually have been sampled. This rule effectively coerces sampling
coverage between 0 and 1. Different levels of sampling can be created by
maximizing the desired coverage of a sample. This desired coverage is
referred to as the `quorum'. After the work of Chao and Jost (2012),
ecologists usually refer to this approach as coverage-based rarefaction.

\paragraph{\texorpdfstring{5.4.3.1. The `inexact' approach to
SQS}{5.4.3.1. The inexact approach to SQS}}\label{the-inexact-approach-to-sqs}

The original description of the SQS algorithm ensured different levels
of coverages by going through the occurrences (or collections) randomly
and aggregating the estimated frequencies of the species that are taken
from the sample until this sum reached the subsampling quorum. John
Alroy (2014) referred to this approach as the `inexact' method to
perform SQS. This is the default way to do SQS.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# sqs with 0.6 quorum}
\NormalTok{sqs0}\FloatTok{.6} \NormalTok{<-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.6}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{,  }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{)}
\CommentTok{#sqs with 0.3 quorum}
\NormalTok{sqs0}\FloatTok{.3} \NormalTok{<-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.3}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{175}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqs0}\FloatTok{.6}\NormalTok{$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqs0}\FloatTok{.3}\NormalTok{$divCSIB, }\DataTypeTok{col=}\StringTok{"green"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], dd$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"raw"}\NormalTok{, }\StringTok{"SQS, q=0.6"}\NormalTok{, }\StringTok{"SQS, q=0.3"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"green"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs1-1.pdf} This procedure
is dependent on the proper estimation of the species' frequencies in the
sampling pool (?frequencies). Alroy (2010) suggested that the observed
frequencies should be adjusted with Good's total sample coverage
estimator \emph{u}, which is dependent on the number of occurrences
(\emph{o}) and the number of single-collection (single-occurrence) taxa
(\emph{\textsuperscript{1}O }).

\[u = 1 - {1}O/o\]

This is the first correction of Alroy (2010, for overall coverage). He
also suggested that for Paleobiology Database occurrences, a different
version of this estimator (\emph{u'}) might be more accurate that is
estimated using the single reference taxa, instead of single-collection
taxa. This estimator is then used to estimate the true frequencies of
species. You can choose between these versions by toggling the
\texttt{singleton} argument between \texttt{"occ"} (default),
\texttt{"ref"} and it can be switched off by setting it to
\texttt{FALSE}. Note that \texttt{"ref"} will require you to provide a
reference variable (\texttt{ref} argument). The discrepancy between the
methods is very small:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsCollSing <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{, }
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }
  \DataTypeTok{singleton=}\StringTok{"occ"}\NormalTok{)}
\NormalTok{sqsRefSing <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{,}
  \DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{)}
\NormalTok{sqsNoSing <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.4}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{singleton=}\OtherTok{FALSE}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsRefSing$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsCollSing$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsNoSing$divCSIB, }\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"SQS, q=0.4"}\NormalTok{, }\StringTok{"SQS, q=0.4, ref"}\NormalTok{, }\StringTok{"SQS, q=0.4, occ"}\NormalTok{),}
  \DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"red"}\NormalTok{), }\DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs2-1.pdf} Alroy (2010)
also mentioned two additional corrections (for \emph{Evenness and
Dominance} and \emph{Single large collections}) that also have minor
effects on the overall results. You can use the \texttt{excludeDominant}
and \texttt{largestColl} arguments to turn these on. Note that you have
to provide a collection variable to make \texttt{largestColl} work,
which is only available if \texttt{excludeDominant=TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsPure <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.5}\NormalTok{,}
  \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{)}
\NormalTok{sqsCorr <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.5}\NormalTok{,}
 \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{,}\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
 \DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{, }\DataTypeTok{excludeDominant=}\NormalTok{T, }\DataTypeTok{largestColl=}\NormalTok{T)}

\CommentTok{# plotting}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsPure$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsCorr$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"uncorrected SQS"}\NormalTok{, }
  \StringTok{"corrected SQS"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqs3-1.pdf}

So far, these calculations were based on occurrence-based rarefaction,
but SQS can be calculated similarly to OW, by tallying the occurrences
collection-by-collection. This can be enforced with the
\texttt{byList=TRUE} option.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sqsByColl <-}\KeywordTok{subsample}\NormalTok{(fossGen, }\DataTypeTok{iter=}\DecValTok{50}\NormalTok{, }\DataTypeTok{q=}\FloatTok{0.5}\NormalTok{,}
 \DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{ref=}\StringTok{"reference_no"}\NormalTok{,}\DataTypeTok{coll=}\StringTok{"collection_no"}\NormalTok{,}
 \DataTypeTok{type=}\StringTok{"sqs"}\NormalTok{, }\DataTypeTok{singleton=}\StringTok{"ref"}\NormalTok{, }\DataTypeTok{excludeDominant=}\NormalTok{T, }\DataTypeTok{largestColl=}\NormalTok{T, }\DataTypeTok{byList=}\OtherTok{TRUE}\NormalTok{)}

\CommentTok{# plotting}
\KeywordTok{tsplot}\NormalTok{(stages, }\DataTypeTok{shading=}\StringTok{"series"}\NormalTok{, }\DataTypeTok{boxes=}\StringTok{"per"}\NormalTok{, }\DataTypeTok{xlim=}\DecValTok{51}\NormalTok{:}\DecValTok{95}\NormalTok{,}
  \DataTypeTok{ylab=}\StringTok{"corrected SIB richness richness"}\NormalTok{, }\DataTypeTok{ylim=}\KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{100}\NormalTok{))}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsByColl$divCSIB, }\DataTypeTok{col=}\StringTok{"blue"}\NormalTok{)}
\KeywordTok{lines}\NormalTok{(stages$mid[}\DecValTok{1}\NormalTok{:}\DecValTok{94}\NormalTok{], sqsCorr$divCSIB, }\DataTypeTok{col=}\StringTok{"black"}\NormalTok{)}
\KeywordTok{legend}\NormalTok{(}\StringTok{"topleft"}\NormalTok{, }\DataTypeTok{legend=}\KeywordTok{c}\NormalTok{(}\StringTok{"by-list SQS"}\NormalTok{, }
  \StringTok{"by-occurrence SQS"}\NormalTok{), }\DataTypeTok{col=}\KeywordTok{c}\NormalTok{(}\StringTok{"blue"}\NormalTok{, }\StringTok{"black"}\NormalTok{), }
  \DataTypeTok{lwd=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{bg=}\StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{handout_files/figure-latex/sqsColl-1.pdf}

\paragraph{5.4.3.2. Concluding remarks on
SQS}\label{concluding-remarks-on-sqs}

SQS is probably the most appropriate method we have today for sampling
standardization of diversity curves. Although the number of potential
influencing factors is high, they do not influence the overall
trajectory of the curves, and the induced variation is almost equal to
the variability that is created by subsampling itself (plot some results
with \texttt{output="dist"}). The systematical evaluation of these
options is still lacking, but we are working on the appropriate testing
framework.

\subsubsection{5.4.4. Subsampling trial
functions}\label{subsampling-trial-functions}

The different subsampling types can be contrasted by comparing the
subsampling trial functions (\texttt{subtrialCR()},
\texttt{subtrialOXW()} and \texttt{subtrialSQS()}).The procedures are of
these functions are also implemented within the \texttt{subsample()}
function, and they can be used to produce one `trial dataset' from the
total sampled data. The output of these function is a logical vector
indicating the rows of the data that should be present in one particular
trial dataset. Future versions of the package will allow the writing and
application of custom subsampling trial functions, with which the
\texttt{subsample()} function will be entirely customizable.

\section{6. Environmental affinities}\label{environmental-affinities}

Most taxa prefer certain environments. Our understanding of
environmental affinities of different taxa depend on the characteristics
of sampling. In some questions the definition of two contrasting
environments suffices, and most hypotheses can be tested with univariate
statistics between two samples. Using the most basic logic, one could
infer that a taxon preferred environment \emph{A} to environment
\emph{B}, all other things being equal, if it occurs more in that
particular environment over its lifetime. This is sometimes referred to
as the majority rule of affinity, and is very straightforward to
implement. In our test example, a number of variables are added based on
the raw data, which express the environmental conditions of the dataset.
For the sake of demonstration, the bathymetric affinities \texttt{bath}
will be calculated. First, we have to omit those occurrences that have
unknown depth conditions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knownBath <-}\StringTok{ }\NormalTok{fossils[fossils$bath!=}\StringTok{"uk"}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\subsection{6.1. Majority rule}\label{majority-rule}

After this simple filtering, the \texttt{affinity()} function can be
applied to the dataset, with specifying the usual arguments, plus the
\texttt{"majority"} method. The function also needs to be notified about
the column (its name. \texttt{env="bath"} in our case) that contains the
binary environmental variable in question:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affMajor <-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"majority"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affMajor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affMajor
## deep shal 
##   25  693
\end{verbatim}

The output of this function is a single character vector, values
specifying the apparently preferred environments and the \texttt{names}
attribute defining the taxon names. \texttt{NA} entries occur when the
function is unable to define an affinity (i.e.~the number of occurrences
from both environments is the same). As you can see, an overwhelming
majority of the taxa have shallow affinities based on this method, but
this is not surprising, as most of the occurrences actually come from
shallow environments.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(knownBath$bath)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  deep  shal 
##  1035 25644
\end{verbatim}

\subsection{6.2. Binomial method}\label{binomial-method}

If sampling is so dominated by shallow occurrences, then the obvious
question that arises is whether the apparent pattern of affinity only is
present because this biased sampling. In order to correct for this
`background' sampling issue, Foote (2006) suggested that the environment
affinity should be determined by comparing the taxon's observed pattern
of occurrences to that present in the total dataset (null sampling
probability of the environment). This approach was also used by
Kiessling and Aberhan (2007) and Kiessling and Kocsis (2015) in later
studies. The sampling probability of the environment is calculated by
taking the proportion of occurrences in the two environments in the
total dataset from the range of the taxon. Under random sampling
conditions, the number of total occurrences and the number among these
that come from an environment is modelled by a binomial distribution.
Given a certain level of confidence one can guess whether the sampled
occurrences of a taxon represent a significantly higher or lower
proportion than predicted by the null probability. The more likely it is
that a simple binomial model can produce the observed success/total
trial ratio, the less we know about the affinity of the taxon. This
approach is implemented by the default \texttt{"binom"} method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affBin1 <-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affBin1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affBin1
## deep shal 
##  135  574
\end{verbatim}

The significance of the binomial tests can be chosen by the
\texttt{alpha} argument that toggles the breadth of proportions that is
considered to be output by the randomness of sampling. The default
\texttt{alpha\ =\ 1} setting (above) will not perform the binomial test.
It will only compare the taxon's observed proportion of occurrences from
the different environments to those observed in the total dataset. The
lower this \texttt{alpha} value is, the less taxa will get an assigned
affinity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affBin0}\FloatTok{.5} \NormalTok{<-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.5}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affBin0}\FloatTok{.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affBin0.5
## deep shal 
##  127  149
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{affBin0}\FloatTok{.1} \NormalTok{<-}\StringTok{ }\KeywordTok{affinity}\NormalTok{(knownBath, }\DataTypeTok{bin=}\StringTok{"stg"}\NormalTok{, }\DataTypeTok{tax=}\StringTok{"genus"}\NormalTok{, }
  \DataTypeTok{method=}\StringTok{"binom"}\NormalTok{, }\DataTypeTok{env=}\StringTok{"bath"}\NormalTok{, }\DataTypeTok{alpha=}\FloatTok{0.1}\NormalTok{)}
\KeywordTok{table}\NormalTok{(affBin0}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## affBin0.1
## deep shal 
##   77   56
\end{verbatim}

Using the standard 95\% percent as alpha level is an arbitrary choice.
As the fossil record has quality issues, a 90\% confidence
(\texttt{alpha\ =\ 0.1}) is preferred in most cases.

\section{Acknowledgements}\label{acknowledgements}

The package was developed in the context of a project on global
paleobiogeography funded by the Deutsche Forschungsgemeinschaft (DFG
project numbers Ko 5382/1-1 and Ko 5382/1-2). The package is also part
of the DFG Research Unit 2332: TERSANE (TEmperature Related Stressors in
Ancient Extinctions). We are thankful to all testers of the package,
including Emilia Jarochowska, Vanessa Roden, Andreas Lauchstedt, and all
participants of the first year International Master's Programme for
Paleobiology at the GeoZentrum Nordbayern, FAU in Erlangen, Germany. We
also thank all enterers of the Paleobiology Database.

\section{References}\label{references}

Alroy, J. (2008). Dynamics of origination and extinction in the marine
fossil record. Proceedings of the National Academy of Science, 105,
11536-11542.

Alroy, J., Aberhan, M., Bottjer, D. J., Foote, M., FÄ‚Ä½rsich, F. T.,
Harries, P. J., Ã¢\euro{}Â¦ Visaggi, C. C. (2008). Phanerozoic Trends in
the Global Diversity of Marine Invertebrates. Science, 321(5885),
97-100. \url{https://doi.org/10.1126/science.1156963}

Alroy, J. (2010). The Shifting Balance of Diversity Among Major Marine
Animal Groups. Science, 329, 1191-1194.
\url{https://doi.org/10.1126/science.1189910}

Alroy, J. (2010b). Geographical, environmental and intrinsic biotic
controls on Phanerozoic marine diversification. Palaeontology
53:1211-1235.\url{https://doi.org/10.1111/j.1475-4983.2010.01011.x}

Alroy, J. (2014). Accurate and precise estimates of origination and
extinction rates. Paleobiology, 40(3), 374-397.
\url{https://doi.org/10.1666/13036}

Alroy, J. (2015). A more precise speciation and extinction rate
estimator. Paleobiology, 41(04), 633-639.
\url{https://doi.org/10.1017/pab.2015.26}

Bell, M. A. (2015). geoscale: Geological Time Scale Plotting. R package
version 2.0. Retrieved from
\url{http://CRAN.R-project.org/package=geoscale}

Foote, M., \& Raup, D. M. (1996). Fossil Preservation and the
Stratigraphic Ranges of Taxa. Paleobiology, 22(2), 121-140.

Chao, A., \& Jost, L. (2012). Coverage-based rarefaction and
extrapolation: standardizing samples by completeness rather than size.
Ecology, 93(12), 2533-2547. \url{https://doi.org/10.1890/11-1952.1}

Foote, M. (1999). Morphological Diversity In The Evolutionary Radiation
Of Paleozoic and Post-Paleozoic Crinoids. Paleobiology, 25(S2), 1-115.

Foote, M. (2000). Origination and Extinction Components of Taxonomic
Diversity: General Problems. Paleobiology, 26(4), 74-102.

Foote, M. (2006). Substrate Affinity and Diversity Dynamics of Paleozoic
Marine Animals. Paleobiology, 32(3), 345-366.
\url{https://doi.org/10.2307/4096955}

Good, I. J. (1953). The Popoulation Frequencies of Species and the
Estimation of Population Parameters. Biometrika, 40(3/4), 237-264.

Ogg, J. G., G. Ogg, and F. M. Gradstein. 2016. A concise geologic time
scale: 2016. Elsevier.

Kiessling, W., \& Aberhan, M. (2007). Environmental determinants of
marine benthic biodiversity dynamics through Triassic-Jurassic time.
Paleobiology, 33(3), 414-434.

Kiessling, W., \& Kocsis, A. T. (2015). Biodiversity dynamics and
environmental occupancy of fossil azooxanthellate and zooxanthellate
scleractinian corals. Paleobiology, 41(3), 402-414.

Kiessling, W., \& Simpson, C. (2011). On the potential for ocean
acidification to be a general cause of ancient reef crises. Global
Change Biology, 17, 56-67.
\url{https://doi.org/10.1111/j.1365-2486.2010.02204.x}

Raup, D. M. (1975). Taxonomic Diversity Estimation Using Rarefaction.
Paleobiology, 1, 333-342. \url{https://doi.org/10.2307/2400135}

Raup, D. M. (1979). Biases in the fossil record of species and genera.
Bulletin of the Carnegie Museum of Natural History, 13, 85-91.

Raup, D. M. (1985). Mathematical Models of Cladogenesis. Paleobiology,
11(1), 42-52.

Sepkoski Jr, J. J. (2002). A compendium of fossil marine animal genera.
Bulletins of American Paleontology, 363, 1-560.


\end{document}
